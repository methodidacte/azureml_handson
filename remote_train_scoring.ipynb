{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade azureml-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade scikit-learn==0.24.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade imbalanced-learn==0.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade azureml-interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install interpret-community[visualization]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade azureml-mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "\n",
    "\n",
    "print(f\"Azure ML SDK Version: {azureml.core.VERSION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "\n",
    "ws = Workspace(subscription_id=\"23376daf-77f3-4195-9649-e223b8072ad9\",\n",
    "              resource_group=\"rg-handsonaml\",\n",
    "              workspace_name=\"wshandsonaml\"\n",
    "              )\n",
    "ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.microsoft.com/fr-fr/azure/machine-learning/how-to-setup-authentication#use-service-principal-authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "\n",
    "print(f\"Azure ML SDK Version: {sklearn.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"exp_remote_training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "\n",
    "exp = Experiment(workspace=ws, name=experiment_name)\n",
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_target_name = \"compute-cluster\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute target creation\n",
    "\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=compute_target_name)\n",
    "    print(\" Cluster already exists\")\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS3_V2',\n",
    "                                                           min_nodes=0, max_nodes=2)\n",
    "    cpu_cluster = ComputeTarget.create(ws, compute_target_name, compute_config)\n",
    "\n",
    "cpu_cluster.wait_for_completion(show_output=True, min_node_count=0, timeout_in_minutes=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve existing compute target\n",
    "\n",
    "from azureml.core.compute import ComputeTarget\n",
    "\n",
    "\n",
    "compute_target = ComputeTarget(workspace=ws, name=compute_target_name)\n",
    "print(compute_target.provisioning_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore, Dataset\n",
    "\n",
    "\n",
    "datastore_name = 'workspaceblobstore'\n",
    "  \n",
    "# retrieve an existing datastore in the workspace by name\n",
    "datastore = Datastore.get(ws, datastore_name)\n",
    "\n",
    "# create a TabularDataset from path(s) in datastore\n",
    "datastore_paths = [(datastore, 'handson/wine.csv')]\n",
    "\n",
    "ds = Dataset.Tabular.from_delimited_files(path=datastore_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.register(workspace=ws,\n",
    "            name='ds_wine_by_code',\n",
    "            description='Wine registered dataset'\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remote training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_folder = 'scripts'\n",
    "\n",
    "import os\n",
    "\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile scripts/train.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix,  plot_roc_curve, f1_score, recall_score\n",
    "import joblib\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "from azureml.core import Run\n",
    "from azureml.core import Dataset\n",
    "\n",
    "# get hold of the current run\n",
    "run = Run.get_context()\n",
    "exp = run.experiment\n",
    "ws = run.experiment.workspace\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--penalty', type=str, default='l2', help='norm')\n",
    "parser.add_argument('--max_iter', type=int, default=10000, help='iterations')\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(\"Argument 1: %s\" % args.penalty)\n",
    "print(\"Argument 2: %s\" % args.max_iter)\n",
    "\n",
    "dataset_name = \"ds_wine_by_code\"\n",
    "dataset = Dataset.get_by_name(ws, name=dataset_name)\n",
    "df = dataset.to_pandas_dataframe()\n",
    "\n",
    "label = \"class\"\n",
    "X = np.array(df.drop(label, axis=1))\n",
    "y = np.array(df[label])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = LogisticRegression(penalty=args.penalty, max_iter=args.max_iter).fit(X=X_train, y=y_train)\n",
    "\n",
    "run.log('train-accuracy', model.score(X_train, Y_train))\n",
    "run.log('test-accurary', model.score(X_test, Y_test))\n",
    "\n",
    "run.log('recall', recall_score(model.predict(X_test), Y_test))\n",
    "run.log('f1', f1_score(model.predict(X_test), Y_test))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=model, filename='outputs/wine_classification_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "\n",
    "trainenv = Environment('wine-training-env')\n",
    "trainenv.python.conda_dependencies = CondaDependencies.create(pip_packages=[\n",
    "    'azureml-defaults',\n",
    "    'inference-schema[numpy-support]',\n",
    "    'joblib',\n",
    "    'numpy',\n",
    "    'pandas',\n",
    "    'sklearn',\n",
    "    'mlflow',\n",
    "    'matplotlib',\n",
    "    'seaborn'\n",
    "])\n",
    "\n",
    "# https://azure.github.io/azureml-cheatsheets/docs/cheatsheets/python/v1/environment/\n",
    "# add pip packages\n",
    "#conda.add_pip_package('pickle')\n",
    "\n",
    "trainenv.save_to_directory('environment/trainenv.yml', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Conda channels : https://docs.anaconda.com/anaconda/user-guide/tasks/using-repositories/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile scripts/trainenv.yml\n",
    "\n",
    "name: trainenv\n",
    "channels:\n",
    "    - anaconda\n",
    "    - conda-forge\n",
    "dependencies:\n",
    "    - python=3.6.9\n",
    "    - pip\n",
    "    - pip:\n",
    "        - azureml-core\n",
    "        - azureml-defaults\n",
    "        - azureml-mlflow\n",
    "        - opencensus-ext-azure>=1.0.1\n",
    "        - inference-schema[numpy-support]\n",
    "        - joblib\n",
    "        - numpy\n",
    "        - pandas\n",
    "        - scikit-learn==0.24.1\n",
    "        - imbalanced-learn==0.8.0\n",
    "        - mlflow\n",
    "        - matplotlib\n",
    "        - seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "\n",
    "trainenv = Environment.from_conda_specification('trainenv', 'scripts/trainenv.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEPRECATED\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "\n",
    "script_params = {\n",
    "    '--penalty': 'l2',\n",
    "    '--max_iter': 10000\n",
    "}\n",
    "\n",
    "estimator = Estimator(source_directory=script_folder,\n",
    "              script_params=script_params,\n",
    "              compute_target=compute_target_name,\n",
    "              environment_definition=trainenv,\n",
    "              entry_script='train.py')\n",
    "\n",
    "#run = exp.submit(config=estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ScriptRunConfig\n",
    "\n",
    "https://docs.microsoft.com/fr-fr/python/api/azureml-core/azureml.core.scriptrunconfig?view=azure-ml-py\n",
    "\n",
    "https://docs.microsoft.com/fr-fr/azure/machine-learning/how-to-migrate-from-estimators-to-scriptrunconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "\n",
    "config = ScriptRunConfig(source_directory=script_folder,\n",
    "                        script='train.py',\n",
    "                        arguments=['--penalty', 'l2', '--max_iter', 10000],\n",
    "                        compute_target=compute_target_name,\n",
    "                        environment=trainenv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = exp.submit(config=config)\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify show_output to True for a verbose log\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> WARNING: A newer version of conda exists. <==\n",
    "  current version: 4.9.2\n",
    "  latest version: 4.10.1\n",
    "\n",
    "Please update conda by running\n",
    "\n",
    "    $ conda update -n base -c defaults conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run.get_metrics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run.get_file_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_model = run.register_model(model_name='wine_classification_model', model_path='outputs/wine_classification_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile scripts/score.py\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import sklearn\n",
    "\n",
    "from inference_schema.schema_decorators import input_schema, output_schema\n",
    "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n",
    "\n",
    "\n",
    "# The init() method is called once, when the web service starts up.\n",
    "#\n",
    "# Typically you would deserialize the model file, as shown here using joblib,\n",
    "# and store it in a global variable so your run() method can access it later.\n",
    "def init():\n",
    "    global model\n",
    "\n",
    "    # The AZUREML_MODEL_DIR environment variable indicates\n",
    "    # a directory containing the model file you registered.\n",
    "    model_filename = 'german_credit_log_model.pkl'\n",
    "    model_path = os.path.join(os.environ['AZUREML_MODEL_DIR'], model_filename)\n",
    "    #ModuleNotFoundError: No module named 'sklearn.externals.joblib'\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "\n",
    "# The run() method is called each time a request is made to the scoring API.\n",
    "#\n",
    "# Shown here are the optional input_schema and output_schema decorators\n",
    "# from the inference-schema pip package. Using these decorators on your\n",
    "# run() method parses and validates the incoming payload against\n",
    "# the example input you provide here. This will also generate a Swagger\n",
    "# API document for your web service.\n",
    "#@input_schema('data', NumpyParameterType(np.array([[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]])))\n",
    "#@output_schema(NumpyParameterType(np.array([0])))\n",
    "\n",
    "def run(raw_data):\n",
    "    data = json.loads(raw_data)['data']\n",
    "    method = json.loads(raw_data)['method']\n",
    "    # Use the model object loaded by init().\n",
    "    result = model.predict(data) if method==\"predict\" else model.predict_proba(data)\n",
    "\n",
    "    # You can return any JSON-serializable object.\n",
    "    return result.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "\n",
    "environment = Environment('german-credit-deploy-env')\n",
    "environment.python.conda_dependencies = CondaDependencies.create(pip_packages=[\n",
    "    'azureml-defaults',\n",
    "    'inference-schema[numpy-support]',\n",
    "    'joblib',\n",
    "    'numpy',\n",
    "    'sklearn'\n",
    "])\n",
    "\n",
    "environment.save_to_directory('environment/infenv.yml', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile scripts/infenv.yml\n",
    "\n",
    "name: project_environment\n",
    "dependencies:\n",
    "  # The python interpreter version.\n",
    "  # Currently Azure ML only supports 3.5.2 and later.\n",
    "- python=3.6.2\n",
    "\n",
    "- pip:\n",
    "  - azureml-defaults\n",
    "  - inference-schema[numpy-support]\n",
    "  - joblib\n",
    "  - numpy\n",
    "  - sklearn\n",
    "channels:\n",
    "- anaconda\n",
    "- conda-forge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "\n",
    "inference_config = InferenceConfig(entry_script='score.py', environment=environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_name = 'wine-custom-srv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Webservice\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.exceptions import WebserviceException\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# Remove any existing service under the same name.\n",
    "try:\n",
    "    Webservice(ws, service_name).delete()\n",
    "except WebserviceException:\n",
    "    pass\n",
    "\n",
    "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1, auth_enabled=False)\n",
    "\n",
    "service = Model.deploy(workspace=ws,\n",
    "                       name=service_name,\n",
    "                       models=[aml_model],\n",
    "                       inference_config=inference_config,\n",
    "                       deployment_config=aci_config)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seulement si auth_enabled=True\n",
    "#print(service.get_keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.swagger_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "input_payload = json.dumps({ \n",
    "    \"data\": [\n",
    "        [14.23,1.71,2.43,15.6,127,2.8,3.06,.28,2.29,5.64,1.04,3.92,1065]\n",
    "    ],\n",
    "    \"method\": \"predict\"  # If you have a classification model, you can get probabilities by changing this to 'predict_proba'.\n",
    "})\n",
    "\n",
    "output = service.run(input_payload)\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "input_payload = json.dumps({ \n",
    "    \"data\": [\n",
    "        [14.23,1.71,2.43,15.6,127,2.8,3.06,.28,2.29,5.64,1.04,3.92,1065]\n",
    "    ],\n",
    "    \"method\": \"predict_proba\"  # If you have a classification model, you can get probabilities by changing this to 'predict_proba'.\n",
    "})\n",
    "\n",
    "output = service.run(input_payload)\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "input_data = \"{\\\"data\\\": [[14.23,1.71,2.43,15.6,127,2.8,3.06,.28,2.29,5.64,1.04,3.92,1065]], \\\"method\\\":\\\"predict\\\"}\"\n",
    "\n",
    "headers = {'Content-Type':'application/json'}\n",
    "\n",
    "# for AKS deployment you'd need to the service key in the header as well\n",
    "#api_key = service.get_keys()[0]\n",
    "#headers = {'Content-Type':'application/json',  'Authorization':('Bearer '+ api_key)} \n",
    "\n",
    "resp = requests.post(service.scoring_uri, input_data, headers=headers)\n",
    "\n",
    "print(\"POST to url\", service.scoring_uri)\n",
    "print(\"prediction:\", resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#service.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
